{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MEFfC0ZxavR"
      },
      "outputs": [],
      "source": [
        "#필요한 라이브러리 호출\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 전처리\n",
        "transform_train = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.RandomRotation(10),\n",
        "                                transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
        "                                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,))])"
      ],
      "metadata": {
        "id": "lI1ZO3cexhLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋을 불러온 후 train, validation으로 분리\n",
        "training_dataset = torchvision.datasets.CIFAR10(\n",
        "  root='./data', \n",
        "  train=True, \n",
        "  download=True, \n",
        "  transform=transform)\n",
        "\n",
        "validation_dataset = torchvision.datasets.CIFAR10(\n",
        "  root='./data', \n",
        "  train=False, \n",
        "  download=True, \n",
        "  transform=transform)\n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(\n",
        "  dataset=training_dataset, \n",
        "  batch_size=100, \n",
        "  shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(\n",
        "  dataset=validation_dataset, \n",
        "  batch_size=100, \n",
        "  shuffle=False)"
      ],
      "metadata": {
        "id": "dv2-dA9ezc9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def im_convert(tensor):\n",
        "    image = tensor.cpu().clone().detach().numpy()\n",
        "    image = image.transpose(1, 2, 0) # transpose : 전치 (행과 열을 바꿈)\n",
        "    image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "    image = image.clip(0, 1) # numpy.clip(min, max) : ar \n",
        "    return image\n",
        "\n",
        "# 클래서 범주 지정\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck') \n",
        "\n",
        "# 이미지 나타내기 \n",
        "dataiter = iter(training_loader) \n",
        "images, labels = dataiter.next()\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "    plt.imshow(im_convert(images[idx]))\n",
        "    ax.set_title(classes[labels[idx].item()])"
      ],
      "metadata": {
        "id": "YXDoGxvK_dKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 정의\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, 1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, 1, padding=1)\n",
        "        self.fc1 = nn.Linear(4*4*64, 500) # 32x32 -> 28x28 -> 14x14 -> 10x10 -> 5x5\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*64)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "hrI_S-Y9OvJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()"
      ],
      "metadata": {
        "id": "sQcyHcW-Z2q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#옵티마이저와 손실 함수 정의 \n",
        "criterion = nn.CrossEntropyLoss() \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "2oMFd9xJz-Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20 # 에포크 설정\n",
        "running_loss_history = []\n",
        "running_corrects_history = []\n",
        "val_running_loss_history = []\n",
        "val_running_corrects_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0.0\n",
        "    val_running_loss = 0.0\n",
        "    val_running_corrects = 0.0\n",
        "    \n",
        "    for inputs, labels in training_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_loss += loss.item()\n",
        "        running_corrects += torch.sum(preds == labels.data) \n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            for val_inputs, val_labels in validation_loader:\n",
        "                val_inputs = val_inputs.to(device)\n",
        "                val_labels = val_labels.to(device)\n",
        "                val_outputs = model(val_inputs)\n",
        "                loss = criterion(val_outputs, val_labels)\n",
        "                \n",
        "                _, val_preds = torch.max(val_outputs, 1)\n",
        "                val_running_loss += loss.item()\n",
        "                val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
        "                \n",
        "        epoch_loss = running_loss/len(training_loader)\n",
        "        epoch_acc = running_corrects.float() / len(training_loader)\n",
        "        running_loss_history.append(epoch_loss)\n",
        "        running_corrects_history.append(epoch_acc.cpu().detach().numpy())\n",
        "        \n",
        "        val_epoch_loss = val_running_loss/len(validation_loader)\n",
        "        val_epoch_acc = val_running_corrects.float() / len(validation_loader)\n",
        "        val_running_loss_history.append(val_epoch_loss)\n",
        "        val_running_corrects_history.append(val_epoch_acc.cpu().detach().numpy())\n",
        "        print('epoch : ', (e+1))\n",
        "        print('training loss: {:.4f}, training acc : {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        print('validation loss: {:.4f}, validation acc : {:.4f}'.format(val_epoch_loss, val_epoch_acc))        \n"
      ],
      "metadata": {
        "id": "YW8CNqrvIAyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6YC0fVlhIJuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHf9NPD5IMZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVKCXgLXIQKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzVHdhYtITeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E2yFC17YIdd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v7B1q8ePIeJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_knDPvCqIlOm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}