{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DctauoujQtRk"
      },
      "source": [
        "예제 1. 이미지 데이터 분류하기\n",
        "==============================\n",
        "> *Multi Layer Perceptron(MLP)* 을 구축하여 이미지 데이터(Fashion MNIST)를 분류해봅시다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_JxK7XZQtRl"
      },
      "source": [
        "* 코드에 필요한 라이브러리를 호출합니다.\n",
        "    1. Numpy\n",
        "    2. Matplotlib\n",
        "    3. torch (Pytorch)\n",
        "    4. torchvision (이미지 처리 함수를 포함하는 pytorch 패키지)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7Hyd02CTZvF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXHA7EkNQtRm"
      },
      "source": [
        "> 학습에 사용될 HyperParameter를 설정합니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMPsGI_GQtRm"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "num_epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brkUAnbsQtRn"
      },
      "source": [
        "> FashionMNIST 데이터셋을 다운로드합니다. torchvision의 datasets클래스에서 현재 많이 사용되는 공용 데이터셋을 배포하고있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlssrFN2U1UN"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "\n",
        "# 데이터셋 내려받기(fashion_mnist)\n",
        "train_dataset  = torchvision.datasets.FashionMNIST(\"FashionMNIST/\", download = True, train = True, transform = transform)\n",
        "test_dataset  = torchvision.datasets.FashionMNIST(\"FashionMNIST/\", download = True, train = False, transform = transform)\n",
        "\n",
        "#fashion_mnist 데이터 데이터로더에 전달\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size)\n",
        "\n",
        "#분류에 사용될 클래스 정의\n",
        "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
        "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'}\n",
        "\n",
        "fig = plt.figure(figsize=(8,8));\n",
        "columns = 4;\n",
        "rows = 5;\n",
        "for i in range(1, columns*rows +1):\n",
        "    img_xy = np.random.randint(len(train_dataset));\n",
        "    img = train_dataset[img_xy][0][0,:,:]\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.title(labels_map[train_dataset[img_xy][1]])\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WVhjkMMQtRn"
      },
      "source": [
        "> Neural Network Model을 정의합니다. 이번 예제의 모델은 MLP로 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoY3mo9RXh_L"
      },
      "outputs": [],
      "source": [
        "#심층신경망 모델 생성\n",
        "class FashionDNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionDNN,self).__init__()\n",
        "        self.fc1 = nn.Linear(in_features=784,out_features=256)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=256,out_features=128)\n",
        "        self.fc3 = nn.Linear(in_features=128,out_features=10)\n",
        "\n",
        "    def forward(self,input_data):\n",
        "        out = input_data.view(-1, 784)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.drop(out)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSIaBTNgQtRo"
      },
      "source": [
        "> Loss Function : CrossEntropy  \n",
        " Optimization Function : Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69q1LF8-XRuv"
      },
      "outputs": [],
      "source": [
        "model = FashionDNN()\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK7S4svaQtRo"
      },
      "source": [
        "> 모델을 epoch 만큼 학습시킨 후 결과를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ve7_ImBgX96_"
      },
      "outputs": [],
      "source": [
        "#모델 학습\n",
        "count = 0\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "\n",
        "predictions_list = []\n",
        "labels_list = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "        train = Variable(images.view(100, 1, 28, 28))\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        outputs = model(train)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        count += 1\n",
        "\n",
        "        if not (count % 50):    \n",
        "            total = 0\n",
        "            correct = 0        \n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                labels_list.append(labels)            \n",
        "                test = Variable(images.view(100, 1, 28, 28))            \n",
        "                outputs = model(test)            \n",
        "                predictions = torch.max(outputs, 1)[1].to(device)\n",
        "                predictions_list.append(predictions)\n",
        "                correct += (predictions == labels).sum()            \n",
        "                total += len(labels)\n",
        "            \n",
        "            accuracy = correct * 100 / total\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "        \n",
        "        if not (count % 500):\n",
        "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf9eZRh2QtRp"
      },
      "source": [
        "> 단일 이미지를 테스트해봅니다. 테스트 데이터셋에서 데이터 하나를 가져와 정확하게 예측하는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50S7hnRTfrmk"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(test_loader))\n",
        "data_num = 0\n",
        "img = x[data_num]\n",
        "plt.imshow(img.view(28,28,1))\n",
        "img = img.to(device)\n",
        "groundtruth = labels_map[y[data_num].item()]\n",
        "print('GroundTruth : ', groundtruth)\n",
        "outputs = model(img)            \n",
        "predictions = torch.max(outputs, 1)[1].to(device)\n",
        "predict = labels_map[predictions.item()]\n",
        "print('Prediction : ',predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKmw_a2gQtRp"
      },
      "source": [
        "> 같은 이미지에서 약간의 회전을 한 후 다시 테스트해보고 정확하게 예측하는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXArm9o2QtRp"
      },
      "outputs": [],
      "source": [
        "t = transforms.RandomRotation(30)\n",
        "new_img = t(img.detach().cpu())\n",
        "plt.imshow(new_img.view(28,28,1))\n",
        "new_img = new_img.to(device)\n",
        "groundtruth = labels_map[y[data_num].item()]\n",
        "print('GroundTruth : ', groundtruth)\n",
        "outputs = model(new_img)            \n",
        "predictions = torch.max(outputs, 1)[1].to(device)\n",
        "predict = labels_map[predictions.item()]\n",
        "print('Prediction : ',predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnbB2BpPQtRp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}