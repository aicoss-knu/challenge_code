{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA0_6y1yYCJC"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters 정의\n",
        "input_size = ???  #28*28\n",
        "num_classes = ???\n",
        "num_epochs = ???\n",
        "learning_rate = ???"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP_model(???)"
      ],
      "metadata": {
        "id": "jVq3I31YYREP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function, optimizer 정의\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
      ],
      "metadata": {
        "id": "O3Vw-YLQYWuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "train_loss = []\n",
        "for epoch in range(1,num_epochs+1):\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        X_batch = ???\n",
        "        \n",
        "        output = model( ??? )\n",
        "        \n",
        "        loss = criterion( ??? )\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "        \n",
        "        if (i+1)% 200 == 0:\n",
        "            print(\"epoch:{}, iter:{} Loss_train:{:.2f}\".format(epoch,i+1, train_loss[-1]))\n",
        "    "
      ],
      "metadata": {
        "id": "UZh-OQs2YZeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss\n",
        "plt.figure()\n",
        "plt.plot(train_loss, label= 'train')\n",
        "plt.legend(loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MVRf3bfpYbJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (X_test, y_test) in enumerate( ? ):\n",
        "        X_test = X_test.reshape(-1, 28*28)\n",
        "\n",
        "        outputs = model(X_test)\n",
        "        outputs_softmax= ? \n",
        "        \n",
        "        predicted = torch.argmax( ? ) # max함수-->(가장 큰 값, 그 값의 index), dim=1: dimension 1을 기준으로\n",
        "        total += y_test.size(0)                             # 총 label의 갯수\n",
        "        correct += (predicted == y_test).sum().item()\n",
        "        \n",
        "       \n",
        "    \n",
        "    accuracy = ? \n",
        "    print('Accuracy of test images: {:.2f} %'.format(accuracy))"
      ],
      "metadata": {
        "id": "0YN_GcBxYde3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}