{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUcoT4ccCOQb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import utils\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "\n",
        "from IPython.display import Image as Display\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "latent_dim = 100\n",
        "n_class = 2\n",
        "lr = 0.0002\n",
        "save_term = 500 \n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "ZIQY4CFwoN90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.Grayscale(1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5), (0.5))])"
      ],
      "metadata": {
        "id": "lTWrI1eRCq4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = './Facemask/'\n",
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "PeEFeAxFjMn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=64, class_num=2):\n",
        "        super(Generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.class_num = class_num\n",
        "        self.embed = nn.Embedding(self.class_num, self.class_num)\n",
        "\n",
        "        self.fclayer = nn.Sequential(\n",
        "            nn.Linear(self.input_dim + self.class_num, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 128 * (self.input_size // 4) * (self.input_size // 4)),\n",
        "            nn.BatchNorm1d(128 * (self.input_size // 4) * (self.input_size // 4)),\n",
        "            nn.ReLU(),)\n",
        "        \n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
        "            nn.Tanh(),)\n",
        "\n",
        "    def forward(self, z, label):\n",
        "        x = torch.cat((z, self.embed(label)), -1)\n",
        "        x = self.fclayer(x)\n",
        "        x = x.view(-1, 128, (self.input_size // 4), (self.input_size // 4))\n",
        "        x = self.deconv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aj9BAQrlCtzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=64, class_num=2):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.class_num = class_num\n",
        "        self.embed = nn.Embedding(self.class_num, 1 * 64 * 64)\n",
        "\n",
        "        def blocks(in_channels, out_channels, bn=True):\n",
        "            block = [nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1)]\n",
        "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            block.append(nn.Dropout2d(0.25))\n",
        "            if bn=True:\n",
        "                block.append(nn.BatchNorm2d(out_channels, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.conv_block = nn.Sequential(\n",
        "            *blocks(2, 32, bn=False),\n",
        "            *blocks(32, 64),\n",
        "            *blocks(64, 128),\n",
        "            *blocks(128, 256),\n",
        "            *blocks(256, 512),)\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(self.input_dim + self.class_num, 64, 4, 2, 1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),)\n",
        "        \n",
        "        self.fclayer = nn.Sequential(\n",
        "            nn.Linear(512 * 2 * 2, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, self.output_dim),\n",
        "            nn.Sigmoid(),)\n",
        "\n",
        "    def forward(self, image, label):\n",
        "        embed = self.embed(label).view((img.size(0), 1, 64, 64))\n",
        "        x = torch.cat((image, embed), 1)\n",
        "        x = self.conv_block(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "sKt1ybrNoF5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "3527j2FyDBhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Generator = Generator()\n",
        "Discriminator = Discriminator()\n",
        "Generator.cuda()\n",
        "Discriminator.cuda()\n",
        "Generator.apply(weights_init_normal)\n",
        "Discriminator.apply(weights_init_normal)\n",
        "adversarial_loss = nn.MSELoss()\n",
        "adversarial_loss.cuda()\n",
        "\n",
        "optimizer_G = torch.optim.Adam(Generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(Discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "B0Gyq9gm8PIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i, (images, label) in enumerate(train_dataloader):\n",
        "        real = torch.cuda.FloatTensor(images.shape[0], 1).fill_(1.0)\n",
        "        fake = torch.cuda.FloatTensor(images.shape[0], 1).fill_(0.0)\n",
        "        real_imgs = images.cuda()\n",
        "        labels = label.cuda()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        z = torch.normal(mean=0, std=1, size=(images.shape[0], latent_dim)).cuda()\n",
        "        generated_labels = torch.randint(0, n_class, (images.shape[0],)).cuda()\n",
        "        generated_imgs = Generator(z, generated_labels)\n",
        "        g_loss = adversarial_loss(Discriminator(generated_imgs, generated_labels), real)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = adversarial_loss(Discriminator(real_imgs, labels), real)\n",
        "        fake_loss = adversarial_loss(Discriminator(generated_imgs.detach(), generated_labels), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        fin = epoch * len(train_dataloader) + i\n",
        "        if fin % save_term == 0:\n",
        "            z = torch.normal(mean=0, std=1, size=(8, latent_dim)).cuda()\n",
        "            labels = torch.LongTensor([i for i in range(n_class) for _ in range(8)]).cuda()\n",
        "            generated_imgs = Generator(z, labels)\n",
        "            save_image(generated_imgs, f\"./results/{fin}.png\", nrow=8, normalize=True)\n",
        "\n",
        "    print(f\"[Epoch {epoch}/{epochs}] [D loss: {d_loss.item():.3f}] [G loss: {g_loss.item():.3f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
      ],
      "metadata": {
        "id": "AK1ApLYDDBl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(Generator.state_dict(), \"Gen_save.pt\")\n",
        "torch.save(Discriminator.state_dict(), \"Disc_save.pt\")"
      ],
      "metadata": {
        "id": "Gq_sQG8YDTCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "generated_labels_0 = torch.cuda.IntTensor(100).fill_(0)\n",
        "gen_result_0 = Generator(z, generated_labels_0)\n",
        "\n",
        "save_image(gen_result_0.data[:50], f'./results/with_mask.png', nrow=10, normalize=True)"
      ],
      "metadata": {
        "id": "QyASa8rGDTFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "generated_labels_1 = torch.cuda.IntTensor(100).fill_(1)\n",
        "gen_result_1 = Generator(z, generated_labels_1)\n",
        "\n",
        "save_image(gen_result_1.data[:50], f'./results/with_no_mask.png', nrow=10, normalize=True)"
      ],
      "metadata": {
        "id": "UNfdkTD6DWpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "    generated_labels_0 = torch.cuda.IntTensor(100).fill_(0)\n",
        "    gen_result_0 = Generator(z, generated_labels_0)\n",
        "\n",
        "    for j in range(50):\n",
        "        save_image(gen_result_0.data[j], f'./results/with_mask/{i * 50 + j}.png', normalize=True)\n",
        "\n",
        "for i in range(10):\n",
        "    z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "    generated_labels_1 = torch.cuda.IntTensor(100).fill_(1)\n",
        "    gen_result_1 = Generator(z, generated_labels_1)\n",
        "\n",
        "    for j in range(100):\n",
        "        save_image(gen_result_1.data[j], f'./results/without_mask/{i * 50 + j}.png', normalize=True)"
      ],
      "metadata": {
        "id": "Ekdil8igDZtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}