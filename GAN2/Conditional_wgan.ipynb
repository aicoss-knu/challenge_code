{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**예제 1. Generator 구성하기**\n",
        "\n",
        "**예제 2. Discriminator 구성하기**\n",
        "\n",
        "**예제 3. 구성한 Generator 와 Discriminator 학습해 새로운 MNIST 이미지 생성**"
      ],
      "metadata": {
        "id": "hx9ulp5qEg7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   필요한 Library Import\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qKnTYehLEiX6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CigIFi4mEWGK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import utils\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "\n",
        "from IPython.display import Image as Display\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   학습에 사용될 Hyper Parameter 설정"
      ],
      "metadata": {
        "id": "ASfG46oWEkYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"Using Device:\", DEVICE)\n",
        "\n",
        "epochs = 200\n",
        "batch_size = 100\n",
        "latent_dim = 100\n",
        "lr = 0.0002\n",
        "save_term = 500 \n",
        "start_time = time.time()"
      ],
      "metadata": {
        "id": "JX0lci5jEkf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   학습에 필요한 MNIST 데이터셋 다운로드"
      ],
      "metadata": {
        "id": "m7Zgu0DNEkoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.Resize([64, 64]), \n",
        "        transforms.Grayscale(1),\n",
        "        transforms.ToTensor(),                     \n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "cifar10_dataset = datasets.CIFAR10(root='./data/', train=True, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(cifar10_dataset, batch_size= batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "j3KvbLBWEkyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Generator 구성"
      ],
      "metadata": {
        "id": "EwnTlvuKEtz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        self.embed = nn.Embedding(10, 10)\n",
        "\n",
        "        def block(input, output, normalize=True):\n",
        "            layer= [nn.Linear(input, output)]\n",
        "            if normalize:\n",
        "                layer.append(nn.BatchNorm1d(output, 0.8))\n",
        "            layer.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layer\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(110, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, 1 * 64 * 64),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z, label):\n",
        "        c = self.embed(label)\n",
        "        x = torch.cat((z, c), -1)\n",
        "        img = self.model(x)\n",
        "        img = img.view(img.size(0), 1, 64, 64)\n",
        "        return img"
      ],
      "metadata": {
        "id": "R5rgtSjEEuzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Discriminator 구성"
      ],
      "metadata": {
        "id": "mqPAbeKJEwKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        self.embed = nn.Embedding(10, 10)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(1 * 64 * 64 + 10, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, label):\n",
        "        x2 = x.view(x.size(0), -1)\n",
        "        c = self.embed(label)\n",
        "        inputs = torch.cat((x2, c), -1)\n",
        "        out = self.model(inputs)\n",
        "        return out"
      ],
      "metadata": {
        "id": "-uZj3EwaEw6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Loss Function 과 Optimization 정의"
      ],
      "metadata": {
        "id": "5i6mmEn6Eyah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "generator.cuda()\n",
        "discriminator.cuda()\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "criterion.cuda()\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "FoXvzG-aEzye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tensor = torch.cuda.FloatTensor\n",
        "LongTensor = torch.cuda.LongTensor\n",
        "\n",
        "def gradient_compute(Discriminator, real, fake, label):\n",
        "    alpha = Tensor(np.random.random((real.size(0), 1, 1, 1)))\n",
        "    label = LongTensor(label)\n",
        "    grad_input = (alpha * real + ((1 - alpha) * fake)).requires_grad_(True)\n",
        "    grad_out = Discriminator(grad_input, label)\n",
        "    fake = Tensor(real.shape[0], 1).fill_(1.0)\n",
        "    fake.requires_grad = False\n",
        "\n",
        "    gradients = autograd.grad(\n",
        "        outputs=grad_input,\n",
        "        inputs=grad_input,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )\n",
        "\n",
        "    gradients = gradients[0].view(gradients[0].size(0), -1)\n",
        "    results= ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "q-aBZBVqJL13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   학습"
      ],
      "metadata": {
        "id": "syzX8WJhE2Kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i, (images, label) in enumerate(train_dataloader):\n",
        "        real_image = images.cuda()\n",
        "        label = label.cuda()\n",
        "        optimizer_D.zero_grad()\n",
        "        z = torch.normal(mean=0, std=1, size=(images.shape[0], latent_dim)).cuda()\n",
        "        fake_image = generator(z, label)\n",
        "        \n",
        "        real_out = discriminator(real_image, label)\n",
        "        # Fake images\n",
        "        fake_out = discriminator(fake_image, label)\n",
        "        # Gradient penalty\n",
        "        gradient = gradient_compute(\n",
        "                            discriminator, real_image.data, fake_image.data,\n",
        "                            label.data)\n",
        "        \n",
        "        loss_D = -torch.mean(real_out) + torch.mean(fake_out) + 10 * gradient\n",
        "        loss_D.backward()\n",
        "        optimizer_D.step()\n",
        "        \n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "\n",
        "        if i % 5 == 0:\n",
        "            fake_image2 = wg_generator(z, label)\n",
        "            fake_out2 = wg_discriminator(fake_image2, label)\n",
        "            loss_G = -torch.mean(fake_out2)\n",
        "            loss_G.backward()\n",
        "            optimizer_G.step()\n",
        "        \n",
        "    print(f\"[Epoch {epoch}/{epochs}] [loss_D: {loss_D.item():.6f}] [loss_G: {loss_G.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
      ],
      "metadata": {
        "id": "AAIRtJLhE1C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   생성하고 싶은 숫자 정한 후 시각화 및 학습결과 확인"
      ],
      "metadata": {
        "id": "FeWxeDBfE42O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.normal(mean=0, std=1, size=(100, latent_dim)).cuda()\n",
        "g_label = torch.cuda.IntTensor(100).fill_(0)\n",
        "fake_image = generator(z, g_label)\n",
        "\n",
        "fake_out = np.reshape(fake_image.data.cpu().numpy()\n",
        "                               [0],(64, 64))\n",
        "\n",
        "plt.imshow(fake_out, cmap = 'gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SeVh9C5qE5pM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}